                  epoch,             train/loss,  metrics/accuracy_top1,  metrics/accuracy_top5,               val/loss,                 lr/pg0,                 lr/pg1,                 lr/pg2
                      1,                0.81647,                0.77083,                      1,                 0.5777,             0.00012138,             0.00012138,             0.00012138
                      2,                0.54758,                0.83333,                      1,                0.51453,             0.00023753,             0.00023753,             0.00023753
                      3,                0.38329,                0.89583,                      1,                0.46751,             0.00034096,             0.00034096,             0.00034096
                      4,                0.32846,                0.89583,                      1,                0.42822,             0.00043166,             0.00043166,             0.00043166
                      5,                0.34869,                0.91667,                      1,                0.41188,             0.00050964,             0.00050964,             0.00050964
                      6,                0.22251,                 0.9375,                      1,                 0.4061,             0.00053728,             0.00053728,             0.00053728
                      7,                0.20886,                0.95833,                      1,                 0.3948,             0.00050194,             0.00050194,             0.00050194
                      8,                 0.1579,                0.91667,                      1,                0.38697,              0.0004666,              0.0004666,              0.0004666
                      9,                0.18003,                0.97917,                      1,                0.38289,             0.00043126,             0.00043126,             0.00043126
                     10,                0.30072,                0.97917,                      1,                 0.3796,             0.00039591,             0.00039591,             0.00039591
                     11,                0.15492,                0.97917,                      1,                0.36568,             0.00036057,             0.00036057,             0.00036057
                     12,                0.21613,                0.97917,                      1,                 0.3665,             0.00032523,             0.00032523,             0.00032523
                     13,                0.19421,                0.97917,                      1,                0.36747,             0.00028988,             0.00028988,             0.00028988
                     14,                0.16789,                      1,                      1,                0.35763,             0.00025454,             0.00025454,             0.00025454
                     15,                0.18764,                0.97917,                      1,                0.36653,              0.0002192,              0.0002192,              0.0002192
                     16,                0.22684,                0.97917,                      1,                0.36725,             0.00018385,             0.00018385,             0.00018385
                     17,                0.20452,                      1,                      1,                0.35547,             0.00014851,             0.00014851,             0.00014851
                     18,                0.19902,                      1,                      1,                0.35649,             0.00011317,             0.00011317,             0.00011317
                     19,                0.14682,                      1,                      1,                0.35752,             7.7826e-05,             7.7826e-05,             7.7826e-05
                     20,                0.13615,                      1,                      1,                0.35397,             4.2483e-05,             4.2483e-05,             4.2483e-05
